WEBVTT

1
00:00:07.230 --> 00:00:08.490
Fireman, Karen: hi how are you.

2
00:00:08.700 --> 00:00:11.250
Capstone Coach 1: Oh good okay now.

3
00:00:11.340 --> 00:00:12.330
Capstone Coach 1: it's just you I mean.

4
00:00:12.719 --> 00:00:15.059
Fireman, Karen: yeah I think others may be having trouble.

5
00:00:15.900 --> 00:00:18.750
Fireman, Karen: i'm on here twice, let me get off the second one hold on i'm leaving one.

6
00:00:19.650 --> 00:00:21.810
Fireman, Karen: Okay, just me hi Hello Leah.

7
00:00:22.320 --> 00:00:23.070
Capstone Coach 1: Oh leo's here.

8
00:00:23.430 --> 00:00:37.950
Fireman, Karen: yeah I have a dumb question that keeps coming up on my on my spider and it doesn't seem to stop anything but it has a lot of um I guess garbage trying to find where it shows up, can I just show you really quickly.

9
00:00:38.160 --> 00:00:39.420
Capstone Coach 1: i'm oh sure sure sure.

10
00:00:39.600 --> 00:00:44.640
Fireman, Karen: yeah the screen it's very weird on here it is so in the middle.

11
00:00:46.860 --> 00:00:48.150
Fireman, Karen: You see this stuff here.

12
00:00:48.240 --> 00:00:49.590
Capstone Coach 1: And then Oh yes, I can see it.

13
00:00:50.130 --> 00:00:52.110
Fireman, Karen: Yes, so the everything works.

14
00:00:53.340 --> 00:00:53.670
Capstone Coach 1: But.

15
00:00:53.760 --> 00:01:07.050
Fireman, Karen: That stuff shows up at the top At first I kept thinking it wasn't working and then I went away and came back, I was like oh it did work so it's very weird it starts off everything's fine and then this that's the epics and that's all good.

16
00:01:08.730 --> 00:01:12.570
Fireman, Karen: And then everything's good until.

17
00:01:13.740 --> 00:01:15.420
Fireman, Karen: Next time mistress doing and again we're.

18
00:01:17.310 --> 00:01:34.440
Fireman, Karen: doing it, I don't see it now, but sometimes Is this all this garbage It just shows up, and it was doing it last week, too, I tried to get you on your Q amp a last week, but I missed, you also had trouble Do you know what this is about, or do I have to worry about it or not.

19
00:01:34.770 --> 00:01:36.000
Capstone Coach 1: Well let's take a look at it.

20
00:01:37.800 --> 00:01:40.140
Capstone Coach 1: move it up a little bit when you see what happened.

21
00:01:40.860 --> 00:01:43.710
Fireman, Karen: Oh sure at the top here that part of the top.

22
00:01:44.100 --> 00:01:45.150
Capstone Coach 1: It says.

23
00:01:46.020 --> 00:01:51.270
Capstone Coach 1: Okay, so it's so it bombed before you got started at the va respond to critique box number one.

24
00:01:52.920 --> 00:01:57.720
Fireman, Karen: Okay, so so something was wrong like maybe I didn't initialize something.

25
00:01:57.780 --> 00:02:00.060
Capstone Coach 1: That look just look at your your thing there.

26
00:02:01.260 --> 00:02:01.620
Capstone Coach 1: well.

27
00:02:01.830 --> 00:02:08.580
Fireman, Karen: Thank you, Kim doing it, but it was doing it last week, let me just see for a second going down real fast to the bottom and see if it the last one I read did it.

28
00:02:09.150 --> 00:02:09.630
Capstone Coach 1: mm hmm.

29
00:02:10.470 --> 00:02:22.530
Fireman, Karen: No right here didn't do it, it just but it didn't do it last week a lot now do it after a while so there's something I didn't initialize realized, it was stopping i'm quite back up to.

30
00:02:22.680 --> 00:02:28.920
Capstone Coach 1: or usually what's happening there is there's a there's a problem with your code in the in the model.

31
00:02:30.000 --> 00:02:33.810
Capstone Coach 1: there's a mismatch between your your code and your data or something.

32
00:02:35.550 --> 00:02:36.270
Capstone Coach 1: So.

33
00:02:37.200 --> 00:02:46.650
Fireman, Karen: Last week happening and everything would work afterwards, but it kept happening in the beginning, the other question I have is what does batch actually mean the batch size, what does it mean.

34
00:02:50.700 --> 00:02:58.260
Capstone Coach 1: that's the Sunday in your model statement that's the batch size it's it if you look at your code on the left hand side here.

35
00:02:58.770 --> 00:02:59.280
Fireman, Karen: uh huh.

36
00:03:02.880 --> 00:03:03.690
Capstone Coach 1: Okay yeah.

37
00:03:07.680 --> 00:03:08.910
Capstone Coach 1: See you have it.

38
00:03:13.890 --> 00:03:18.360
Fireman, Karen: I know we can change that parameter, but I wasn't sure what it what it referred to, what do you.

39
00:03:18.630 --> 00:03:22.230
Capstone Coach 1: Think I think it's referring to they were says filters is.

40
00:03:22.680 --> 00:03:26.070
Capstone Coach 1: And you have filters equal to 64 basically.

41
00:03:26.910 --> 00:03:27.360
Fireman, Karen: Right.

42
00:03:27.870 --> 00:03:28.740
Fireman, Karen: And what is.

43
00:03:29.040 --> 00:03:31.830
Capstone Coach 1: Wait a minute you change that size to 256.

44
00:03:31.890 --> 00:03:38.820
Fireman, Karen: I did change it, I, but I just want to location was doing it, I was 121 28, but I wonder what it meant.

45
00:03:39.510 --> 00:03:47.070
Capstone Coach 1: Well, if you take a look down at the fit statement, so you have compile and below that is the fifth good on your code there.

46
00:03:51.090 --> 00:03:53.910
Capstone Coach 1: You see, it says batch size is equal to size.

47
00:03:54.330 --> 00:03:56.670
Fireman, Karen: i'm missing that which line, am I looking for because i'm missing.

48
00:03:57.000 --> 00:03:57.810
Capstone Coach 1: To 19.

49
00:03:59.010 --> 00:04:03.480
Fireman, Karen: Okay, two to 19 yeah batch physical size, yes.

50
00:04:04.500 --> 00:04:04.830
Fireman, Karen: Oh.

51
00:04:06.420 --> 00:04:12.270
Fireman, Karen: Oh size is 128 so I wasn't actually there that's pretty funny Okay, but what does it mean, though.

52
00:04:14.880 --> 00:04:24.390
Capstone Coach 1: That every pot it there's a certain number of batches that are run and that number controls, the number of batches that are run to fit the data.

53
00:04:25.020 --> 00:04:40.050
Capstone Coach 1: And in this case it's set to 128, which is a good number for these data, if you made it smaller it's going to run slower will have more more batches actually and if you make it larger little run faster because you'll have fewer batches that are being run.

54
00:04:41.490 --> 00:04:43.140
Fireman, Karen: Okay, so it's really the number of.

55
00:04:44.310 --> 00:04:49.890
Capstone Coach 1: Information, if you want to know if you want to know how many observations are being run in each batch.

56
00:04:50.250 --> 00:05:01.200
Capstone Coach 1: You take that number 128 and then divided into 60,000 we get a big number yeah so i'm.

57
00:05:01.590 --> 00:05:02.970
Fireman, Karen: God I got you.

58
00:05:03.330 --> 00:05:04.770
Capstone Coach 1: yeah okay.

59
00:05:04.830 --> 00:05:17.520
Fireman, Karen: terrific Okay, thank you um yeah cuz I when I was changing I went to know what it what is actually doing and the filters, what does that mean oh that was up here, so we have filters equals 64 i'm sorry.

60
00:05:20.640 --> 00:05:22.140
Fireman, Karen: it's over here I guess here.

61
00:05:22.140 --> 00:05:29.820
Capstone Coach 1: it's the number of filters in the convolution you're basically when you're running a convolution like you have several convolution layers here.

62
00:05:30.000 --> 00:05:30.450
Fireman, Karen: Right.

63
00:05:30.540 --> 00:05:38.430
Capstone Coach 1: And you have filter size of the number of filters is set on each one of them, and your code it's set to 60 for all of them.

64
00:05:38.910 --> 00:05:46.950
Capstone Coach 1: Right, you could change that you could have fewer or alarm more filters in the convolution that controls, how many.

65
00:05:49.500 --> 00:06:00.000
Capstone Coach 1: filters, there are placed over each photograph because what's happening in convolution is that it's moving the the filters by smoothing the photograph by rather.

66
00:06:00.480 --> 00:06:10.320
Capstone Coach 1: By putting a filter on top of the photograph and this case it's a three by three filter because your your size your kernel size is three.

67
00:06:11.400 --> 00:06:11.970
Fireman, Karen: Okay.

68
00:06:12.480 --> 00:06:14.580
Capstone Coach 1: No, sorry the statements that you've got there.

69
00:06:14.940 --> 00:06:34.770
Capstone Coach 1: Right, so that means that you're the filter is a three by three window it's placed on top of the of the photograph and moved across the photograph and how many of filters view, have you got 64 is what's what this is saying.

70
00:06:35.820 --> 00:06:50.550
Capstone Coach 1: 64 different ones, each one of them has weights right each each filter has weights nine weights, so those were what's being estimated in the and the neural network process here to get the best filtered image.

71
00:06:55.110 --> 00:06:58.140
Fireman, Karen: In the cm E weights on this bottle.

72
00:06:59.340 --> 00:07:04.050
Fireman, Karen: In the filter the weights, on the other, model are on the neurons is that right.

73
00:07:05.340 --> 00:07:06.780
Capstone Coach 1: What other model you're talking about.

74
00:07:07.170 --> 00:07:09.570
Fireman, Karen: The one we were doing first yesterday.

75
00:07:09.660 --> 00:07:12.390
Capstone Coach 1: Not this fall so that's a different approach to that.

76
00:07:13.410 --> 00:07:20.520
Capstone Coach 1: there's no filtering of the photographs at all all you're doing is taking the raw data from the photographs and you run that through a.

77
00:07:21.120 --> 00:07:36.810
Capstone Coach 1: Free forward a neural network on nlp multi layer preceptor on network and there's no attempt to filter the images at all, and as a result, what you'll see is the number of leads in that network are huge.

78
00:07:37.590 --> 00:07:38.340
Fireman, Karen: Right so.

79
00:07:39.000 --> 00:07:48.390
Capstone Coach 1: When you when you run the convolution it reduces the number of weights, that you have to that are being estimated and that's what gives it a better fit in general.

80
00:07:49.140 --> 00:08:03.450
Capstone Coach 1: Because you're getting better results are the same results with using fewer weights and that's being done by filtering by smoothing the images and basically collapsing them down to a smaller dimension.

81
00:08:04.470 --> 00:08:06.090
Fireman, Karen: Okay, one last question on that.

82
00:08:06.090 --> 00:08:11.280
Fireman, Karen: So so here this part of the side these parameters over here on the side.

83
00:08:12.720 --> 00:08:26.070
Fireman, Karen: So in the other model, they were neurons or you have another preceptor plus I called neurons so they were neurons are an A so I know they add up to 115 I did I am I checked it out.

84
00:08:26.670 --> 00:08:27.090
Capstone Coach 1: You know.

85
00:08:27.330 --> 00:08:30.540
Fireman, Karen: There were these the neurons still.

86
00:08:30.570 --> 00:08:32.850
Capstone Coach 1: Are the know that's the number of waits.

87
00:08:33.210 --> 00:08:33.900
Fireman, Karen: waits now.

88
00:08:33.990 --> 00:08:35.130
Capstone Coach 1: yeah so.

89
00:08:35.460 --> 00:08:43.290
Capstone Coach 1: that's the number of lines that are in the network, you can think of it that way in the in the nlp network every line connecting you know one.

90
00:08:43.830 --> 00:09:01.290
Capstone Coach 1: Data point to an Iran and that kind of thing Those are all individual weights and there'll be an estimated to optimize the prediction of the the digit you know this case you have 10 different possible predictions, and so you have two different approaches that nlp approach.

91
00:09:02.700 --> 00:09:13.890
Capstone Coach 1: can produce good results in this case it produces fair results bit of overfitting, I think, and in this case, what we're doing in the second case in the convolution case.

92
00:09:14.460 --> 00:09:34.200
Capstone Coach 1: What we're doing is we're actually pre processing the photograph itself we're reducing the size of the number of bits that are being used to represent they put a graph originally it's 28 by 28 and we gradually shrink them down at the bottom there it's.

93
00:09:34.650 --> 00:09:35.460
Fireman, Karen: Right right.

94
00:09:36.480 --> 00:09:36.840
Capstone Coach 1: yeah.

95
00:09:37.680 --> 00:09:38.490
Fireman, Karen: yeah yeah.

96
00:09:38.910 --> 00:09:39.750
Capstone Coach 1: yeah no.

97
00:09:40.200 --> 00:09:44.280
Fireman, Karen: And then, lastly, this nonsense in here I forgot what is that not be.

98
00:09:48.960 --> 00:09:49.440
Capstone Coach 1: That.

99
00:09:50.580 --> 00:09:54.720
Capstone Coach 1: that's used, I think, with color photographs so number of channels and.

100
00:09:55.470 --> 00:09:58.620
Capstone Coach 1: It basically was not specified here so that's what it's saying.

101
00:09:59.370 --> 00:10:00.420
Fireman, Karen: Okay, I just do that.

102
00:10:01.110 --> 00:10:01.530
Capstone Coach 1: yeah okay.

103
00:10:01.860 --> 00:10:04.860
Fireman, Karen: i'm done hogging the floor i'm going to give it back Thank you day.

104
00:10:04.890 --> 00:10:05.640
Capstone Coach 1: Sure yeah.

105
00:10:06.720 --> 00:10:10.080
Capstone Coach 1: Okay, Jim how about you have you got any questions for the line.

106
00:10:10.950 --> 00:10:27.810
Jim Clark: I I think a general question I think i'm going to try the try this assignment over the over the next week I guess the base cases the what we're working with and then start tweaking.

107
00:10:29.340 --> 00:10:31.680
Jim Clark: Is i'm trying to decide whether to treat.

108
00:10:32.040 --> 00:10:34.620
Capstone Coach 1: OK, I can help you with i'll help you with that i'll help you.

109
00:10:34.860 --> 00:10:36.150
Jim Clark: Know tangibly or just tweak.

110
00:10:36.150 --> 00:10:39.330
Jim Clark: One thing you know i'm a nod you turn you.

111
00:10:39.660 --> 00:10:41.490
Jim Clark: i'm thinking you learn learn just.

112
00:10:41.580 --> 00:10:43.530
Jim Clark: Make one change at a time.

113
00:10:44.160 --> 00:10:44.730
Jim Clark: There was.

114
00:10:44.760 --> 00:10:49.740
Capstone Coach 1: Some ups, let me show you let me show you share my screen with you here and show you a little bit.

115
00:10:51.060 --> 00:10:54.750
Capstone Coach 1: get to that question will share okay there we go.

116
00:11:13.140 --> 00:11:17.730
Capstone Coach 1: Okay, so i'm gonna i'm gonna clear clear off the.

117
00:11:19.920 --> 00:11:20.880
Capstone Coach 1: Wait a minute, let me.

118
00:11:22.080 --> 00:11:23.310
Capstone Coach 1: Clear the console.

119
00:11:25.020 --> 00:11:32.070
Capstone Coach 1: The right hand side there we go, so this is the CNN program on the left hand side CNN.

120
00:11:33.690 --> 00:11:34.410
Capstone Coach 1: and

121
00:11:36.420 --> 00:11:44.970
Capstone Coach 1: Here we go, I think this is the one that's most curious when we talked last night you'll remember that I showed you a.

122
00:11:46.620 --> 00:11:49.590
Capstone Coach 1: An excel spreadsheet and i'm gonna i'm going to open that up here.

123
00:11:50.040 --> 00:11:51.030
Jim Clark: versus the guessing.

124
00:11:51.750 --> 00:12:02.190
Capstone Coach 1: Right, and this is, this is my way of running you know different scenarios and recording, then what I found.

125
00:12:03.210 --> 00:12:07.350
Capstone Coach 1: And I think you will find it if you use the same spreadsheet.

126
00:12:09.330 --> 00:12:17.370
Capstone Coach 1: you're going to find some information here, so what you can see what i'm recording I record the number of the pox.

127
00:12:18.240 --> 00:12:28.650
Capstone Coach 1: The BAT size which very you can vary, and then the configuration of the different layers is captured in these columns and then the total number of weights.

128
00:12:29.190 --> 00:12:41.250
Capstone Coach 1: The misclassification for train and validation for the training accuracy and validation accuracy, which is basically calculated from these misclassification numbers, right here.

129
00:12:42.240 --> 00:12:52.380
Capstone Coach 1: And then, and then you have the difference in the training and validation accuracy and the execution time, so this is a sort of thing that I would record.

130
00:12:53.370 --> 00:13:13.830
Capstone Coach 1: The what's going to be different, is what happens in this area, right here how many layers you have and how many preceptor bronze or neurons you put in each layer Now this is for the nlp case, what I can what you can do here is, you can say okay i'm going to create a new.

131
00:13:14.820 --> 00:13:18.150
Jim Clark: In Syria, a word vote for the scene in case.

132
00:13:19.350 --> 00:13:27.870
Jim Clark: What so you can just create another word but clone that and just create another word but that that's for the.

133
00:13:28.260 --> 00:13:31.980
Capstone Coach 1: Exactly and that's what I was going to do here is just.

134
00:13:33.210 --> 00:13:34.050
Capstone Coach 1: I think.

135
00:13:35.850 --> 00:13:40.230
Capstone Coach 1: How do I claim this champ to I thought I thought I went to insert or you just.

136
00:13:40.230 --> 00:13:40.920
Capstone Coach 1: gave you.

137
00:13:41.280 --> 00:13:46.110
Jim Clark: So click on the worksheet Okay, we can do this it's like a worksheet right click.

138
00:13:46.980 --> 00:13:54.690
Jim Clark: Oh, when you would you could do is you can copy that working paste it and then just wipe out the roads.

139
00:13:55.710 --> 00:13:56.190
Capstone Coach 1: Okay.

140
00:13:56.880 --> 00:14:00.300
Capstone Coach 1: So I can just go like this copy the columns right.

141
00:14:00.570 --> 00:14:02.640
Jim Clark: You copy it and then go and see to.

142
00:14:03.090 --> 00:14:05.040
Capstone Coach 1: You then go to the cto and.

143
00:14:07.050 --> 00:14:07.530
Capstone Coach 1: face it.

144
00:14:07.830 --> 00:14:10.380
Fireman, Karen: For forgot how many can we don't have to even do that just go to the top.

145
00:14:10.380 --> 00:14:10.830
Fireman, Karen: corner.

146
00:14:11.160 --> 00:14:13.470
Jim Clark: Just really good at a one and hit paste.

147
00:14:15.030 --> 00:14:18.090
Capstone Coach 1: Oh just good a one year and his face like that.

148
00:14:19.410 --> 00:14:20.400
Capstone Coach 1: There we go, we got it.

149
00:14:20.880 --> 00:14:25.980
Jim Clark: And then wipe out all the roads 10 through 21.

150
00:14:26.670 --> 00:14:28.440
Capstone Coach 1: uh huh OK.

151
00:14:28.920 --> 00:14:29.430
Jim Clark: And then.

152
00:14:29.820 --> 00:14:30.060
let's.

153
00:14:31.110 --> 00:14:33.810
Jim Clark: regulate the title on the workbook or.

154
00:14:34.350 --> 00:14:37.920
Jim Clark: or a tile above so tracker which she is which.

155
00:14:38.220 --> 00:14:38.580
Capstone Coach 1: Okay.

156
00:14:38.880 --> 00:14:39.840
Jim Clark: Good I do all the time.

157
00:14:40.500 --> 00:14:47.130
Capstone Coach 1: And veteran Okay, so we just got I left the first row in there is a example of what I want to do.

158
00:14:47.430 --> 00:14:53.040
Capstone Coach 1: right then down here i'm going to rename and what i'm going to do is i'm going to rename this guy CNN.

159
00:14:54.780 --> 00:14:57.840
Capstone Coach 1: And the first guy i'm going to rename nlp.

160
00:14:59.010 --> 00:15:00.810
Jim Clark: To great idea I like that.

161
00:15:01.590 --> 00:15:06.000
Capstone Coach 1: Because there's a reason is these middle columns here are going to be a little different.

162
00:15:07.530 --> 00:15:15.090
Capstone Coach 1: You have different information they know you have convolution going on, so the filter size and all that sort of thing comes into play.

163
00:15:15.690 --> 00:15:34.230
Capstone Coach 1: So this is the format that I would use for them LP data case situation now what you could do if you're using that code you'll notice that I tried l one here and I that's the regularization using the one I did not try l to.

164
00:15:35.490 --> 00:15:46.170
Capstone Coach 1: So you could, for instance, you could rerun these scenarios right in here, using nail to instead of L want to see what kind of difference if any.

165
00:15:46.680 --> 00:15:55.410
Capstone Coach 1: may not make a difference that it might make right now what we were just trying to do that I was trying to do is just compare running the old one versus using drop it.

166
00:15:55.890 --> 00:16:08.250
Capstone Coach 1: drop it as the other form of regularization and you'll you'll notice that, in some cases I use the third layer, which is the middle layer and some cases I did not, most of the time, I did not.

167
00:16:09.270 --> 00:16:22.410
Capstone Coach 1: I was just running 784 and 10 so the output layers down and then nothing in between, but there are a few cases, so you can see from here that it's not exhaustive, all the possible examples are not in here.

168
00:16:23.040 --> 00:16:33.780
Capstone Coach 1: You could change any of this and rerun a different scenario, for instance, you could instead of having a bad silo sorry layer one hears all 784.

169
00:16:34.920 --> 00:16:43.530
Capstone Coach 1: So I was what i've always been why I was wondering what would happen if we cut that in half now that's the number of neurons in the first layer

170
00:16:44.100 --> 00:17:07.290
Capstone Coach 1: Nice, I chose 784 because we have 784 inputs a 2828 photograph pests 784 digits or pixels so that's why I chose 784 but maybe maybe some multiple is a different number would would work or you notice, I did use something larger up here and it didn't really help.

171
00:17:08.340 --> 00:17:24.060
Capstone Coach 1: So I know that but going under this I didn't try it out, and you know it might be might be, if you drop this up to half and then maybe put in a middle layer right here, maybe would do better, I don't know I haven't tried that so obviously.

172
00:17:25.350 --> 00:17:35.730
Capstone Coach 1: Now here well we're going to need, we will need to set this up a little differently, we still have the pox and we still have that size.

173
00:17:36.180 --> 00:17:52.200
Capstone Coach 1: But instead of layer one layer one here, you really have convolution one so i'm going to change that to sue and V1 and then you have pooling P O l one, and then you have convolution two.

174
00:17:53.820 --> 00:17:56.220
Capstone Coach 1: And then you have pooling after that.

175
00:17:58.590 --> 00:18:03.030
Capstone Coach 1: Then you have completion three I believe this.

176
00:18:04.140 --> 00:18:08.580
Capstone Coach 1: And now i'm going to have to add some columns here so i'm going to put in a.

177
00:18:11.040 --> 00:18:13.170
Capstone Coach 1: How do we do that okay somewhere around here.

178
00:18:13.260 --> 00:18:16.590
Jim Clark: Or we just click on the column on the right click insert.

179
00:18:18.600 --> 00:18:19.050
Jim Clark: insert.

180
00:18:19.620 --> 00:18:20.400
Capstone Coach 1: off okay.

181
00:18:22.950 --> 00:18:24.420
Capstone Coach 1: Something like that so.

182
00:18:24.510 --> 00:18:27.150
Jim Clark: i've actually just push it to the right.

183
00:18:28.800 --> 00:18:32.820
Capstone Coach 1: So in v3 and then pool three, I think it is.

184
00:18:35.100 --> 00:18:38.400
Capstone Coach 1: And then we go to flatten.

185
00:18:40.470 --> 00:18:42.510
Capstone Coach 1: And then one more.

186
00:18:45.450 --> 00:18:48.480
Capstone Coach 1: So the this will be Latin.

187
00:18:48.930 --> 00:18:51.540
Jim Clark: Latin and then it will be or.

188
00:18:52.380 --> 00:18:52.740
alpha.

189
00:18:56.070 --> 00:19:14.670
Capstone Coach 1: So I think that's the way it's structured, if you look at the code on this problem we have convolution to convolution to conclusion to and then flatten Oh, there is no pool three oh it just goes out with flattens everything down so that isn't there.

190
00:19:16.710 --> 00:19:28.200
Capstone Coach 1: That there we go and now for each one of these, you have different combinations so for comic con one here, the number of filters is 64.

191
00:19:29.130 --> 00:19:44.280
Capstone Coach 1: And for con, and this is the default conditions that are currently in the in the code, so you have 6864 filters and all all of these and in the pool you have.

192
00:19:45.900 --> 00:19:46.260
Capstone Coach 1: Read.

193
00:19:46.530 --> 00:19:46.920
The book.

194
00:19:48.750 --> 00:19:48.990
Capstone Coach 1: Is.

195
00:19:49.530 --> 00:19:51.510
Jim Clark: Renewing your line.

196
00:19:51.900 --> 00:19:54.060
1832.

197
00:19:55.980 --> 00:20:12.630
Capstone Coach 1: Exactly all the way across to and then flatten there is no parameters there, but that, then you have 10 neurons in the output side, so you could you could, by the way, there is no and regularization and the code right now.

198
00:20:13.740 --> 00:20:24.660
Capstone Coach 1: that's something else that could be added, you could put regularization after any of these condition, you know convolutions here, you could you could put a regularization into their.

199
00:20:25.590 --> 00:20:40.290
Capstone Coach 1: know the way you do that, actually, is here, and the con con CEO in the 2d there's an extra parameter and it's it's called Colonel activation I believe so, you want to.

200
00:20:41.370 --> 00:20:47.310
Capstone Coach 1: Know it's down here you'll see it in the code actually in this example you just say activation I know.

201
00:20:49.020 --> 00:21:00.360
Capstone Coach 1: Colonel regularization as Colonel regularization equals and then you'd put l one or two and then in parentheses, the actual value for the penalty.

202
00:21:01.620 --> 00:21:06.360
Capstone Coach 1: And I think I showed that, in the other code if I go to switch over to the other code.

203
00:21:09.150 --> 00:21:10.830
Capstone Coach 1: Right see where is that.

204
00:21:12.000 --> 00:21:12.990
Capstone Coach 1: Right up here.

205
00:21:14.310 --> 00:21:31.920
Capstone Coach 1: make it a little larger for you yeah so in the other code you'll see that it says, Colonel regularization is none, you can contain you can change that to Colonel regularization is equal to, and you know one option would be l one.

206
00:21:34.320 --> 00:21:43.260
Capstone Coach 1: l one and then in in parenthesis one E minus six one to the minus six and.

207
00:21:44.820 --> 00:21:54.600
Capstone Coach 1: That would be coming yeah so that's how you do regularization inside of the, why is it complaining about this.

208
00:21:58.230 --> 00:21:59.370
Fireman, Karen: isn't he quotes.

209
00:21:59.730 --> 00:22:02.700
Capstone Coach 1: Oh, it doesn't like the little l that wants.

210
00:22:03.030 --> 00:22:04.650
Capstone Coach 1: To go go, I think.

211
00:22:06.450 --> 00:22:08.220
Capstone Coach 1: Oh no.

212
00:22:09.270 --> 00:22:09.990
Capstone Coach 1: This is.

213
00:22:11.250 --> 00:22:35.310
Capstone Coach 1: You have to say, regular cheese appear in the inputs its regular risers regular risers and then you so you have to have this input here from tensorflow charisse important regular risers and then down here, where I was working instead of putting just Ellen one where to go.

214
00:22:38.850 --> 00:22:41.130
Capstone Coach 1: Okay, oh that's for the.

215
00:22:41.310 --> 00:22:42.000
Jim Clark: Red dot.

216
00:22:43.740 --> 00:22:47.070
Capstone Coach 1: For you Okay, so I would have to go.

217
00:22:49.260 --> 00:22:50.190
Capstone Coach 1: Something.

218
00:22:51.690 --> 00:22:56.130
Capstone Coach 1: Right exactly you have to do for i'm going to move this over a little bit.

219
00:22:59.640 --> 00:23:02.760
Capstone Coach 1: Instead of L one, you would have to say, regular risers.

220
00:23:05.640 --> 00:23:19.920
Capstone Coach 1: Doc and then you can use the l one L two or l one l to you can you can use them both and if you're using just l one l to in parenthesis you to have the penalty.

221
00:23:21.330 --> 00:23:34.050
Capstone Coach 1: And if you're using the other one which is a combination of L one l to you would have to finish these one for one and one for L two inside of these brackets parenthesis.

222
00:23:34.800 --> 00:23:48.420
Capstone Coach 1: But ordinarily just l one or just lt by itself would be sufficient to experiment with, so this is what you're seeing here, you would do that and let's go back to the other code.

223
00:23:49.650 --> 00:23:59.010
Capstone Coach 1: And i'm pretty sure this is going to be the same right in here after conflict inside of the con con 2d.

224
00:24:02.550 --> 00:24:07.230
Capstone Coach 1: Oh upside didn't copy it okay let's try copying this again.

225
00:24:11.790 --> 00:24:12.660
Capstone Coach 1: Go here.

226
00:24:14.520 --> 00:24:30.180
Capstone Coach 1: And there we go that should be accepted the what so what this is going to do, I will test it out here, and just as i'm going to run this just to make sure that my I don't get an error here but Oh, let me make sure the inputs are up there, the regularization is.

227
00:24:30.570 --> 00:24:31.350
Jim Clark: Is that yeah.

228
00:24:31.620 --> 00:24:52.140
Capstone Coach 1: It is it's a so we're good with that and so now, if I run this what should happen, and now I would have to experiment, a little bit about the the penalty the regularization number in this case, one a minus six we might want to make that bigger or smaller, so it doesn't.

229
00:24:53.850 --> 00:25:02.430
Capstone Coach 1: It doesn't show up in the model description, but it is being used because it wasn't Reno so rejected the syntax is OK.

230
00:25:03.750 --> 00:25:15.240
Capstone Coach 1: But the up here doesn't really tell you anything about that now the other thing you can experiment with is instead of doing that form of regularization you could use.

231
00:25:17.430 --> 00:25:17.820
Fireman, Karen: let's see.

232
00:25:18.000 --> 00:25:23.520
Capstone Coach 1: model.ad and drop out.

233
00:25:26.220 --> 00:25:27.120
Capstone Coach 1: And drop out.

234
00:25:30.210 --> 00:25:31.950
Capstone Coach 1: Now the the small.

235
00:25:33.420 --> 00:25:34.350
Capstone Coach 1: Okay that's.

236
00:25:43.410 --> 00:25:46.050
Capstone Coach 1: It looks like it wants me to put a layers in here.

237
00:25:47.130 --> 00:25:50.040
Capstone Coach 1: Doc drop out yeah that's what it wanted.

238
00:25:52.290 --> 00:26:08.850
Capstone Coach 1: That this is required because of the way the import statements I don't have one from Cracow, so this is another form of regularization and what's going to happen here is instead of using an l one penalty it's going to drop some of the weights coming out of the second convolution.

239
00:26:10.290 --> 00:26:20.520
Capstone Coach 1: let's turn this just to see, I think the box here is set to to, by the way, so there's, the results are the runs past, but the results are not very good.

240
00:26:21.960 --> 00:26:25.560
Fireman, Karen: To work when I got an error with that.

241
00:26:26.190 --> 00:26:26.820
Capstone Coach 1: With what.

242
00:26:27.390 --> 00:26:28.470
Fireman, Karen: When I tried it for the regular.

243
00:26:29.970 --> 00:26:30.540
Capstone Coach 1: Okay.

244
00:26:30.660 --> 00:26:34.980
Fireman, Karen: here's for regular or equal to work people Reza legalizers thought.

245
00:26:36.450 --> 00:26:38.820
Fireman, Karen: I did anybody get that to work as I look.

246
00:26:42.390 --> 00:26:44.220
Fireman, Karen: At the model that ad right yeah.

247
00:26:45.420 --> 00:26:46.320
Fireman, Karen: But the comment.

248
00:26:48.150 --> 00:26:54.030
Capstone Coach 1: Are you do you see what I did I did it I put it, you put it inside the CEO and the to the it's not separate.

249
00:26:55.260 --> 00:26:55.740
Capstone Coach 1: that's why.

250
00:26:57.570 --> 00:26:59.220
Capstone Coach 1: You see the way i've done it here.

251
00:27:00.360 --> 00:27:01.020
Capstone Coach 1: see that.

252
00:27:02.850 --> 00:27:07.020
Fireman, Karen: Inside the car okay I didn't get there i'm sorry Okay, thank you.

253
00:27:08.100 --> 00:27:19.440
Capstone Coach 1: And then the drop out that's done a little differently that's that's done done as a separate layer a separate action, and so you see here in the.

254
00:27:20.130 --> 00:27:33.030
Capstone Coach 1: The output, the description of the network, the word dropout explicit explicitly appears showing that it's being used and where it's being used in the configuration here so.

255
00:27:34.350 --> 00:27:38.850
Capstone Coach 1: You can experiment with putting dropout after any of these con convolutions.

256
00:27:39.900 --> 00:27:44.790
Capstone Coach 1: You can put one or two in the combination.

257
00:27:46.380 --> 00:28:06.390
Capstone Coach 1: that's I would use one or the other but probably not both you mean regularization should work in either case, and then you might want to see Is it better to use l one or is it better to use drop out, but using them together in the same network of we're doing here is a little weird.

258
00:28:07.830 --> 00:28:17.460
Capstone Coach 1: Usually I say probably use one or not, the other, the main thing you can experiment with, though, is the number of filters right here.

259
00:28:18.570 --> 00:28:33.960
Capstone Coach 1: You change the number of filters and the number of weights changes dramatically so originally this was 64 i'm going to change it back to 64 so or you can see, the number of weights here is like 80,000.

260
00:28:35.670 --> 00:28:45.510
Capstone Coach 1: Now that I have dropped out in here so drop out is going to read them may reduce some of the weights, but yeah it's 80,000.

261
00:28:47.190 --> 00:29:02.910
Capstone Coach 1: The the big numbers, you can see where the bid, the first layer knots not the only 640 weights, but the the second convolution and the third convolution they really increase the number of weights that we're estimating right.

262
00:29:03.600 --> 00:29:23.190
Capstone Coach 1: The trick to this business is to get a good filter but not too many weights, and so one way to achieve that is to actually eliminate like the third convolution So if you eliminated the third convolution then you're going to reduce the number of weights by 36,000 37,000 almost 37 right.

263
00:29:24.450 --> 00:29:31.530
Capstone Coach 1: So we have three layers of con convolution you that's maybe you only need to maybe only need one.

264
00:29:32.310 --> 00:29:52.800
Capstone Coach 1: So you can run those scenarios and, of course, you could run those scenarios split just commenting out the second or the third convolution here The other thing you can do is instead of using 64 let's see what happens if I put in 32 and and we'll see here i'm gonna stop it.

265
00:29:53.940 --> 00:29:54.750
Capstone Coach 1: rerun.

266
00:29:56.340 --> 00:30:11.220
Capstone Coach 1: And look what happens so instead of 30 almost 37,000 the number of weights in the second layer of convolution is 18,000 and the total number of weights goes from age and 61 see that.

267
00:30:12.630 --> 00:30:19.230
Capstone Coach 1: And are we going to get a better fit or worse fit I don't know a good guide to have a run the whole thing.

268
00:30:20.400 --> 00:30:26.070
Capstone Coach 1: So that's that's the sort of thing I was, I was thinking you might do and going back to the spreadsheet.

269
00:30:29.310 --> 00:30:44.700
Capstone Coach 1: Where are we here yeah so you could, for example, put the one that I just did I run that ran 32 filters and convolution number one instead of 64 and then the total number of weights, instead of.

270
00:30:45.780 --> 00:30:55.980
Capstone Coach 1: 80,000, or so it drops down to 61 514.

271
00:30:57.000 --> 00:31:13.530
Capstone Coach 1: And now i'd have to actually run it all the way out to to get these other numbers that are here, the actual classification rates, but the here we have the number of the box and the batch size, so the number of the box let's see where would that be.

272
00:31:15.060 --> 00:31:25.530
Capstone Coach 1: that's set down here in the code down here's number of the boxes so we'll make that 20 and the batch size is 128.

273
00:31:26.580 --> 00:31:27.270
Capstone Coach 1: let's see.

274
00:31:29.190 --> 00:31:34.290
Capstone Coach 1: yeah that would this would be 128 32 is going to be slow.

275
00:31:35.310 --> 00:31:52.380
Capstone Coach 1: So we did that I would also record in summer in your sheet the value you use for l one if you did yo it use it and the dropout rate and in our code, the dropout rate we have is you can experiment with that too that's Point two.

276
00:31:53.730 --> 00:32:08.760
Capstone Coach 1: 0.2, so this is not 45 it's 0.2 like that just record that now, if I use dropout so I use dropout in this case I put it right after the the second convolution right here.

277
00:32:09.870 --> 00:32:13.680
Capstone Coach 1: And so i'm going what i'm going to do, then, is i'm going to add an extra column.

278
00:32:15.300 --> 00:32:16.080
Capstone Coach 1: here.

279
00:32:17.370 --> 00:32:18.240
Capstone Coach 1: and

280
00:32:20.640 --> 00:32:21.780
Capstone Coach 1: move this over.

281
00:32:24.060 --> 00:32:26.790
Capstone Coach 1: And here i'm going to call this drop out.

282
00:32:29.280 --> 00:32:38.760
Capstone Coach 1: Well i'm going to call this regular regularization to, and so, if a regularization to we used to drop out right here.

283
00:32:39.390 --> 00:32:55.530
Capstone Coach 1: Now, after four regularization number one I need to add another column in between these two like this, and I would put in REG one Monica and for this guy we have it set as l one.

284
00:32:57.090 --> 00:33:10.470
Capstone Coach 1: l one regularization so this This describes the conditions that we that we have here in this particular case, so we're using 3432 filters and convolution regularization available on.

285
00:33:11.520 --> 00:33:13.500
Capstone Coach 1: Max pool to two by two.

286
00:33:14.730 --> 00:33:18.930
Capstone Coach 1: For the second layer we're using 64 filters and drop out.

287
00:33:19.980 --> 00:33:24.510
Capstone Coach 1: And then, for the third layer also 64 flatten and then the output.

288
00:33:25.980 --> 00:33:34.560
Capstone Coach 1: So, and then this, these are the numbers that are going to support the dropout and the regularization here okay.

289
00:33:36.120 --> 00:33:38.670
Capstone Coach 1: So if I go back to the code now.

290
00:33:40.200 --> 00:33:42.120
Capstone Coach 1: and run it for real.

291
00:33:44.100 --> 00:33:45.660
Capstone Coach 1: Wait a minute did I already run it.

292
00:33:49.110 --> 00:33:56.400
Capstone Coach 1: No, that was just too weak box so i'm going to start restart the kernel just to make sure.

293
00:33:57.720 --> 00:33:58.800
Capstone Coach 1: everything looks good.

294
00:34:04.530 --> 00:34:05.130
Capstone Coach 1: Okay.

295
00:34:06.600 --> 00:34:09.300
Capstone Coach 1: and run okay like that.

296
00:34:14.100 --> 00:34:14.490
Capstone Coach 1: So.

297
00:34:14.790 --> 00:34:26.340
Jim Clark: we'll see like what you could do is set up, you know eight or 10 different cases and just give them different model number yeah and just let it run overnight.

298
00:34:26.820 --> 00:34:28.050
Capstone Coach 1: Right yeah.

299
00:34:28.290 --> 00:34:29.760
Jim Clark: and listen pick it up in the morning.

300
00:34:29.790 --> 00:34:32.700
Capstone Coach 1: Or if you're doing your do your homework, or something like that.

301
00:34:32.910 --> 00:34:48.210
Capstone Coach 1: This code, by the way, has the ability to run two models and there's a model, one and a model to so you could configure you can you can knock off two of them right there and then cannot change the conditions and run another and and then I would just use the spreadsheet that that.

302
00:34:49.530 --> 00:34:50.940
Capstone Coach 1: That we're working with here.

303
00:34:52.020 --> 00:35:02.970
Capstone Coach 1: As as a way of recording that information and then, when you when you turn in your homework and just turn in the spreadsheet and maybe a few words.

304
00:35:03.450 --> 00:35:18.270
Capstone Coach 1: The best case was so and so or regularization didn't help you know the best convolution was so, and so you know that kind of thing and and the spreadsheet I think we can probably see can we save this as a PDF.

305
00:35:19.200 --> 00:35:21.210
Capstone Coach 1: yeah you can, and is it come.

306
00:35:21.210 --> 00:35:22.560
Fireman, Karen: On you can print it that way.

307
00:35:22.800 --> 00:35:28.380
Capstone Coach 1: yeah Okay, and as well let's see it should be i'm trying to say I can save it as a pod pedia.

308
00:35:28.740 --> 00:35:31.530
Capstone Coach 1: And I assume that it would it's readable so.

309
00:35:32.700 --> 00:35:52.590
Capstone Coach 1: That would be cool just one sheet and or if you're going to have to you you're going to do both a bookcase scenarios me i'm just i'm mainly curious about the CNN because I didn't run this I played a little bit around them LP and the results that came out are kind of expected.

310
00:35:54.030 --> 00:36:04.200
Capstone Coach 1: But here I didn't try any of this and I suspect, in other cases where i've done this, I find that the you don't need three layers of convolution.

311
00:36:05.040 --> 00:36:23.160
Capstone Coach 1: Probably two are going to work pretty well so i'm betting my bets are that if you if you mask off the third layer of convolution and work just with the first two you'll probably get better results, but hey they haven't tried it Donna.

312
00:36:25.770 --> 00:36:26.400
Jim Clark: Thank you for.

313
00:36:27.030 --> 00:36:27.870
Capstone Coach 1: Okay yeah.

314
00:36:29.400 --> 00:36:31.650
Capstone Coach 1: Are you class just going there, otherwise okay.

315
00:36:33.270 --> 00:36:33.600
Fireman, Karen: Is he.

316
00:36:34.920 --> 00:36:35.910
Jim Clark: I guess we're just.

317
00:36:36.510 --> 00:36:40.020
Jim Clark: yeah i've been for the capstone I think my slides.

318
00:36:40.590 --> 00:36:41.370
Capstone Coach 1: Okay, actually.

319
00:36:41.550 --> 00:36:43.320
Jim Clark: be like my father in good shape now.

320
00:36:44.730 --> 00:36:51.300
Capstone Coach 1: Right right, so I guess most of you have your capstones next week Is that correct.

321
00:36:52.500 --> 00:36:53.310
Fireman, Karen: A lot of people do.

322
00:36:54.360 --> 00:36:59.490
Capstone Coach 1: yeah i'm looking at some names here, I have, I have some next week next.

323
00:37:00.510 --> 00:37:12.120
Capstone Coach 1: Tuesday and Wednesday, it looks like and Thursday and and then the the last few days, I think, after that so okay well good, well, good luck on all of that for you.

324
00:37:13.140 --> 00:37:19.110
Capstone Coach 1: And I know you're going to be greatly relieved when this is all hope for sure.

325
00:37:20.730 --> 00:37:25.500
Capstone Coach 1: But you know the funny thing is that when you finish your capstone, then you have your peer presentation.

326
00:37:26.820 --> 00:37:27.300
Capstone Coach 1: yeah no.

327
00:37:29.640 --> 00:37:30.540
Capstone Coach 1: that's not as.

328
00:37:32.040 --> 00:37:35.220
Capstone Coach 1: stressful I guess after a few of the cast on you're done.

329
00:37:36.840 --> 00:37:38.730
Jim Clark: or like it'd be a lot shorter and the.

330
00:37:39.900 --> 00:37:42.960
Jim Clark: Things that maybe it's a purpose, and those are the main.

331
00:37:43.950 --> 00:37:51.600
Capstone Coach 1: yeah yeah and so i'm looking forward to seeing that so if there are any other questions or comments.

332
00:37:52.590 --> 00:37:53.400
Fireman, Karen: Thank you very much.

333
00:37:53.550 --> 00:37:58.170
Capstone Coach 1: Well, thank you for showing up for a while there, I thought I was gonna I was gonna be all alone.

334
00:37:59.430 --> 00:38:02.520
Fireman, Karen: I couldn't get you I was trying to sign on but I couldn't get you.

335
00:38:03.330 --> 00:38:06.030
Capstone Coach 1: yeah yeah I don't know what happened.

336
00:38:07.620 --> 00:38:13.680
Capstone Coach 1: I don't know well, I I signed on and no I don't know I guess it didn't think I was the host or something.

337
00:38:14.190 --> 00:38:19.740
Fireman, Karen: Right you right if you don't sign in and you're just in then it's waiting for the host but it's waiting for you yeah.

338
00:38:19.770 --> 00:38:23.130
Fireman, Karen: Okay, just that it was waiting for the host sign it if it's you and i'm like.

339
00:38:25.980 --> 00:38:26.520
Capstone Coach 1: All right.

340
00:38:27.030 --> 00:38:28.410
Capstone Coach 1: Thank you so much okay.

341
00:38:28.440 --> 00:38:30.510
Jim Clark: thanks for the best suggestions.

342
00:38:30.660 --> 00:38:32.790
Capstone Coach 1: yeah thanks for coming appreciate.

343
00:38:33.330 --> 00:38:34.170
Fireman, Karen: appreciate it bye.

344
00:38:34.590 --> 00:38:35.310
Capstone Coach 1: bye bye now.

